--------SCRIPT----------------------------
So in this week, I am working on some commonly used Loss functions, and evaluation metrics in the recommendation system.
As shown in the page, I will first introduce some evaluation metrics.
By the way, I find the evaluation methods for recommendation system is very similar to information retrieval system, which is also used to ranked the retrieved results to the user. The mean difference between them, I think should be that in IR system, we know what is the users looking for, but we need to predict the user's interest in the recommendation system.
Precision @k, Recall@k are the simplest metrics. As shown in the figure, this is the figure I got from a information retrieval course, which uses very similar evaluation method.
k is a constant here, indicate the position we need to cut off the recommendation list, then calculate the recall and precision, In the next item-prediction, only a single ground truth item is relevant, so the recall@k will be one if the expected item appear before position k. This value can measure how well the model can capture the groundtruth item.

MAP, MRR.
As you can see here, before get MAP, we should calculate the average precision in test collections, because our task is the next-item prediction, so there is only one relevant item, therefore, no need for calculating Average precision in each test data. To calculate the MAP in our task, we firstly calculate the precision@k value in each test data where k equals to the ranked position of the groundtruth item. the mean of all these values is MAP.

Mean Reciprocal rank, only consider the first relevant item and other parts is the same as MAP, which is the same as MAP in our task, because next-item prediction only has a single groundtruth item.

This value refers to how well a model ranks the ground-truth items.


nDCG,
normalize the tradional DCG value with the ideal condition before position k. Again, for a single relevant item task like ours, this value can be simply calculate using this equation, if the ground-truth item occurs before position k, if the item does not appear in the recommendation list after cuting off, the value will be zero.

This value indicates how strongly an item is recommended.

Here is the main idea of iDCG@k, but in our task, it will be less complex, because we only have one relevant item.

Hit Ratio, in our task, is the same as recall.


There some different loss functions can be used.

In TOP1 loss, as you can see in the loss function, the first part is to penalize when irrelevant items has a higher score than the ground-truth item.
and the second part can be seen a kind of regularization.

BPR loss is the negative logarithm of the probability the positive item is ranked higher than the negative items. As you can see from the equation, if the ranked score for the ground-truth item is much higher than the negative samples, we will get a lower loss.

CCE loss also called categorical cross entropy, measuring the differentce between predicted distribution and the true distribution of the target labels. Softmax, cost problem. As you can see if the softmax for the ground truth is closed to 1, the loss value will also close to 0.

Hinge loss aims to ensure that the score for a positive item (a good recommendation) is higher than the score for negative items (bad recommendations) by a certain margin. where ùê∂ is the set of recommendations containing item ùëñ, while ùêπ is the set of recommendations not containing i
There are two main components. The aim for the left part is to make the scores for good recommendations as close to 1 as possible. The aim for the right equation is to make the scores for bad recommendations as close to 0 as possible. ùõæ is a parameter to balance the impacts of the two parts of errors.

the results on different datasets are varied.

The result of differnt loss functions on different datasets are varied. Therefore to figure out which loss function is suitable for our task will be further tested.


To mitigate the discrepancy between training and inference As training progresses, the probability decreases, and the model is more likely to receive its own predictions as inputs.


--------QUESTION--------------------------
Q1: how to apply scheduled sampling to the next-item prediction sequential model?
In my opinion the output will be a single item(or a small set of items) as the next interaction rather than generating an entire sequence, Or we may need a ranked list for all items, but in this progress, the model will not need to apply generate other things based what it has already generated. So how to apply it?
