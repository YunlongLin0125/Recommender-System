{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "ml_20m_path = '../../../../datasets/ml-20m'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "file_path = ml_20m_path + '/ratings.csv'\n",
    "data = pd.read_csv(file_path, encoding='latin-1', sep=',', engine='python', index_col='userId')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "        movieId  rating   timestamp\nuserId                             \n1             2     3.5  1112486027\n1            29     3.5  1112484676\n1            32     3.5  1112484819\n1            47     3.5  1112484727\n1            50     3.5  1112484580\n...         ...     ...         ...\n138493    68954     4.5  1258126920\n138493    69526     4.5  1259865108\n138493    69644     3.0  1260209457\n138493    70286     5.0  1258126944\n138493    71619     2.5  1255811136\n\n[20000263 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n    <tr>\n      <th>userId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>3.5</td>\n      <td>1112486027</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>29</td>\n      <td>3.5</td>\n      <td>1112484676</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>32</td>\n      <td>3.5</td>\n      <td>1112484819</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>47</td>\n      <td>3.5</td>\n      <td>1112484727</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>3.5</td>\n      <td>1112484580</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>68954</td>\n      <td>4.5</td>\n      <td>1258126920</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>69526</td>\n      <td>4.5</td>\n      <td>1259865108</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>69644</td>\n      <td>3.0</td>\n      <td>1260209457</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>70286</td>\n      <td>5.0</td>\n      <td>1258126944</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>71619</td>\n      <td>2.5</td>\n      <td>1255811136</td>\n    </tr>\n  </tbody>\n</table>\n<p>20000263 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "actions = data\n",
    "actions = actions.groupby('movieId').filter(lambda  x: len(x) >= 5)\n",
    "actions = actions.groupby('userId').filter(lambda  x: len(x) >= 5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "actions = actions.groupby('userId', group_keys=False).apply(lambda  x: x.sort_values('timestamp'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "        movieId  rating   timestamp\nuserId                             \n1           924     3.5  1094785598\n1           919     3.5  1094785621\n1          2683     3.5  1094785650\n1          1584     3.5  1094785656\n1          1079     4.0  1094785665\n...         ...     ...         ...\n138493     6534     3.0  1260209908\n138493    53464     4.0  1260209920\n138493     1275     3.0  1262378552\n138493     6996     3.0  1262378555\n138493      405     3.0  1262378572\n\n[19984024 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n    <tr>\n      <th>userId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>924</td>\n      <td>3.5</td>\n      <td>1094785598</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>919</td>\n      <td>3.5</td>\n      <td>1094785621</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2683</td>\n      <td>3.5</td>\n      <td>1094785650</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1584</td>\n      <td>3.5</td>\n      <td>1094785656</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1079</td>\n      <td>4.0</td>\n      <td>1094785665</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>6534</td>\n      <td>3.0</td>\n      <td>1260209908</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>53464</td>\n      <td>4.0</td>\n      <td>1260209920</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>1275</td>\n      <td>3.0</td>\n      <td>1262378552</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>6996</td>\n      <td>3.0</td>\n      <td>1262378555</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>405</td>\n      <td>3.0</td>\n      <td>1262378572</td>\n    </tr>\n  </tbody>\n</table>\n<p>19984024 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(20, 8540, 144.2935816250641)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = data.groupby('userId')\n",
    "min = 100000\n",
    "max = 0\n",
    "total = 0\n",
    "for i in range(1, actions.index.max()):\n",
    "    total += len(actions.loc[i])\n",
    "    if len(data.loc[i]) < min:\n",
    "        min = len(actions.loc[i])\n",
    "    if len(data.loc[i]) > max:\n",
    "        max = len(actions.loc[i])\n",
    "min, max, total/actions.index.max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "usermap = dict()\n",
    "usernum = 0\n",
    "itemmap = dict()\n",
    "itemnum = 0\n",
    "# reorder the userid and itemid (keep the same step with original SASRec code)\n",
    "for _id, row in actions.iterrows():\n",
    "    if _id in usermap:\n",
    "        userid = usermap[_id]\n",
    "    else:\n",
    "        usernum += 1\n",
    "        userid = usernum\n",
    "        usermap[_id] = userid\n",
    "\n",
    "    if row.movieId in itemmap:\n",
    "        itemid = itemmap[row.movieId]\n",
    "    else:\n",
    "        itemnum += 1\n",
    "        itemid = itemnum\n",
    "        itemmap[row.movieId] = itemid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(138493, 18345)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usermap.__len__(), itemmap.__len__()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "actions['movieId'] = actions['movieId'].map(itemmap)\n",
    "actions.index = actions.index.map(usermap)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "        movieId  rating   timestamp\nuserId                             \n1             1     3.5  1094785598\n1             2     3.5  1094785621\n1             3     3.5  1094785650\n1             4     3.5  1094785656\n1             5     4.0  1094785665\n...         ...     ...         ...\n138493      872     3.0  1260209908\n138493      797     4.0  1260209920\n138493     2336     3.0  1262378552\n138493      946     3.0  1262378555\n138493      789     3.0  1262378572\n\n[19984024 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n    <tr>\n      <th>userId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3.5</td>\n      <td>1094785598</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>3.5</td>\n      <td>1094785621</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>3.5</td>\n      <td>1094785650</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>3.5</td>\n      <td>1094785656</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>4.0</td>\n      <td>1094785665</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>872</td>\n      <td>3.0</td>\n      <td>1260209908</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>797</td>\n      <td>4.0</td>\n      <td>1260209920</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>2336</td>\n      <td>3.0</td>\n      <td>1262378552</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>946</td>\n      <td>3.0</td>\n      <td>1262378555</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>789</td>\n      <td>3.0</td>\n      <td>1262378572</td>\n    </tr>\n  </tbody>\n</table>\n<p>19984024 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "sas_data = actions.drop('rating', axis=1, inplace=False).drop('timestamp', axis=1, inplace=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "with open('ml-20m.txt', 'w') as f:\n",
    "    for _id in set(sas_data.index):\n",
    "        for movie_id in sas_data.loc[_id].movieId:\n",
    "            f.write('%d %d\\n' % (_id, movie_id))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "        movieId\nuserId         \n1             1\n1             2\n1             3\n1             4\n1             5\n...         ...\n138493      872\n138493      797\n138493     2336\n138493      946\n138493      789\n\n[19984024 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n    </tr>\n    <tr>\n      <th>userId</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>872</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>797</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>2336</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>946</td>\n    </tr>\n    <tr>\n      <th>138493</th>\n      <td>789</td>\n    </tr>\n  </tbody>\n</table>\n<p>19984024 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sas_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "userMaxTime = actions.groupby('userId').timestamp.max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "userId\n1         1112486201\n2          974821014\n3          945176099\n4          840879654\n5          851617728\n             ...    \n138489    1352990179\n138490     975545576\n138491    1247183347\n138492    1115351450\n138493    1262378572\nName: timestamp, Length: 138493, dtype: int64"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userMaxTime"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "day = 86400\n",
    "num_day = 7\n",
    "userSplitTime = userMaxTime - num_day  * day"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "userId\n1         1111881401\n2          974216214\n3          944571299\n4          840274854\n5          851012928\n             ...    \n138489    1352385379\n138490     974940776\n138491    1246578547\n138492    1114746650\n138493    1261773772\nName: timestamp, Length: 138493, dtype: int64"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userSplitTime"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _id \u001B[38;5;129;01min\u001B[39;00m actions\u001B[38;5;241m.\u001B[39mindex:\n\u001B[0;32m      3\u001B[0m     split_time \u001B[38;5;241m=\u001B[39m userSplitTime\u001B[38;5;241m.\u001B[39mloc[_id]\n\u001B[1;32m----> 4\u001B[0m     user_seq \u001B[38;5;241m=\u001B[39m actions[\u001B[43m(\u001B[49m\u001B[43mactions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m_id\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m&\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mactions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimestamp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m<\u001B[39;49m\u001B[43m \u001B[49m\u001B[43msplit_time\u001B[49m\u001B[43m)\u001B[49m]\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _id \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m      6\u001B[0m         train_seq \u001B[38;5;241m=\u001B[39m user_seq\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2113\u001B[0m, in \u001B[0;36mNDFrame.__array_ufunc__\u001B[1;34m(self, ufunc, method, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   2109\u001B[0m \u001B[38;5;129m@final\u001B[39m\n\u001B[0;32m   2110\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__array_ufunc__\u001B[39m(\n\u001B[0;32m   2111\u001B[0m     \u001B[38;5;28mself\u001B[39m, ufunc: np\u001B[38;5;241m.\u001B[39mufunc, method: \u001B[38;5;28mstr\u001B[39m, \u001B[38;5;241m*\u001B[39minputs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any\n\u001B[0;32m   2112\u001B[0m ):\n\u001B[1;32m-> 2113\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arraylike\u001B[38;5;241m.\u001B[39marray_ufunc(\u001B[38;5;28mself\u001B[39m, ufunc, method, \u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:265\u001B[0m, in \u001B[0;36marray_ufunc\u001B[1;34m(self, ufunc, method, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m    262\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# for binary ops, use our custom dunder methods\u001B[39;00m\n\u001B[1;32m--> 265\u001B[0m result \u001B[38;5;241m=\u001B[39m maybe_dispatch_ufunc_to_dunder_op(\u001B[38;5;28mself\u001B[39m, ufunc, method, \u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    266\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m:\n\u001B[0;32m    267\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\ops_dispatch.pyx:113\u001B[0m, in \u001B[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py:72\u001B[0m, in \u001B[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m     68\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[0;32m     70\u001B[0m other \u001B[38;5;241m=\u001B[39m item_from_zerodim(other)\n\u001B[1;32m---> 72\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:76\u001B[0m, in \u001B[0;36mOpsMixin.__rand__\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;129m@unpack_zerodim_and_defer\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__rand__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__rand__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[1;32m---> 76\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_logical_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mroperator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrand_\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:6254\u001B[0m, in \u001B[0;36mSeries._logical_method\u001B[1;34m(self, other, op)\u001B[0m\n\u001B[0;32m   6251\u001B[0m lvalues \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values\n\u001B[0;32m   6252\u001B[0m rvalues \u001B[38;5;241m=\u001B[39m extract_array(other, extract_numpy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, extract_range\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m-> 6254\u001B[0m res_values \u001B[38;5;241m=\u001B[39m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlogical_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6255\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_construct_result(res_values, name\u001B[38;5;241m=\u001B[39mres_name)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:397\u001B[0m, in \u001B[0;36mlogical_op\u001B[1;34m(left, right, op)\u001B[0m\n\u001B[0;32m    395\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m na_logical_op(lvalues, rvalues, op)\n\u001B[0;32m    396\u001B[0m     \u001B[38;5;66;03m# error: Cannot call function of unknown type\u001B[39;00m\n\u001B[1;32m--> 397\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m \u001B[43mfiller\u001B[49m\u001B[43m(\u001B[49m\u001B[43mres_values\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[operator]\u001B[39;00m\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res_values\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:364\u001B[0m, in \u001B[0;36mlogical_op.<locals>.fill_bool\u001B[1;34m(x, left)\u001B[0m\n\u001B[0;32m    361\u001B[0m         x[mask] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    363\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m left \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m is_bool_dtype(left\u001B[38;5;241m.\u001B[39mdtype):\n\u001B[1;32m--> 364\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mbool\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    365\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_seq = None\n",
    "for _id in actions.index:\n",
    "    split_time = userSplitTime.loc[_id]\n",
    "    user_seq = actions[(actions.index == _id) & (actions.timestamp < split_time)]\n",
    "    if _id == 1:\n",
    "        train_seq = user_seq\n",
    "    else:\n",
    "        train_seq = pd.concat([train_seq, user_seq], ignore_index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_seq"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SASRec handling\n",
    "Only use implicit feedback in the sequence of items"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "day = 86400\n",
    "usernum = actions.index.max()\n",
    "split_percent = 0.9\n",
    "k = 25\n",
    "split_index = int(len(actions.loc[k]) * split_percent)\n",
    "train_seq = actions.loc[k].iloc[:split_index]\n",
    "target_seq = actions.loc[k].iloc[split_index:]\n",
    "target_seq.timestamp.max() - train_seq.timestamp.max()\n",
    "# actions.loc[1].timestamp.max() -"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "userMaxTime = actions.groupby('userId').timestamp.max()\n",
    "userActLength = actions.groupby('userId').size()\n",
    "split_index = (userActLength * split_percent).astype(int)\n",
    "userMaxTime, split_index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "window_size = []\n",
    "for i in range(1 ,actions.index.max() + 1):\n",
    "    cur_seq = actions.loc[i]\n",
    "    split = split_index.loc[i]\n",
    "    train_seq = cur_seq.iloc[:split]\n",
    "    target_seq = cur_seq.iloc[split:]\n",
    "    window_size.append(target_seq.iloc[-1].timestamp - train_seq.iloc[-1].timestamp)\n",
    "\n",
    "seq_avg_length= userActLength.mean()\n",
    "seq_avg_length # , window_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def data_partition_window(fname, valid_percent, test_percent, train_percent):\n",
    "    if valid_percent + test_percent > 0.6:\n",
    "        print('the percent you select for val/test are too high')\n",
    "        return None\n",
    "    valid_start = 1 - valid_percent - test_percent\n",
    "    test_start = 1 - test_percent\n",
    "    train_start = 1 - train_percent\n",
    "    usernum = 0\n",
    "    itemnum = 0\n",
    "    User = defaultdict(list)\n",
    "    user_train = {}\n",
    "    user_valid = {}\n",
    "    user_test = {}\n",
    "    # assume user/item index starting from 1\n",
    "    f = open('%s.txt' % fname, 'r')\n",
    "    # read from each line\n",
    "    for line in f:\n",
    "        u, i = line.rstrip().split(' ')\n",
    "        u = int(u)\n",
    "        i = int(i)\n",
    "        usernum = max(u, usernum)\n",
    "        itemnum = max(i, itemnum)\n",
    "        User[u].append(i)\n",
    "        # count user and items\n",
    "    # read from each user\n",
    "    count = 0\n",
    "    for user in User:\n",
    "        nfeedback = len(User[user])\n",
    "        if nfeedback < 3:\n",
    "            user_train[user] = User[user]\n",
    "            user_valid[user] = []\n",
    "            user_test[user] = []\n",
    "        else:\n",
    "            # select the whole training seq\n",
    "            # user_train[user] = User[user][:-2]\n",
    "            seq_len = len(User[user])\n",
    "            valid_index = int(seq_len * valid_start)\n",
    "            test_index = int(seq_len * test_start)\n",
    "            if valid_index == test_index:\n",
    "                user_train[user] = User[user]\n",
    "                user_valid[user] = []\n",
    "                user_test[user] = []\n",
    "            else:\n",
    "                train_seq = User[user][: valid_index]\n",
    "                valid_seq = User[user][valid_index: test_index]\n",
    "                test_seq = User[user][test_index:]\n",
    "                train_seq_length =len(train_seq)\n",
    "                split_index = int(train_seq_length * train_start)\n",
    "                input_seq = train_seq[:split_index]\n",
    "                target_seq = train_seq[split_index:]\n",
    "                for target in target_seq:\n",
    "                    count+=1\n",
    "                    user_train[count] = input_seq + [target]\n",
    "                user_valid[user] = []\n",
    "                user_valid[user]+= valid_seq\n",
    "                user_test[user] = []\n",
    "                user_test[user]+= test_seq\n",
    "    return [user_train, user_valid, user_test, usernum, itemnum]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = data_partition_window('ml-1m', 0.1, 0.1, 0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[user_train, user_valid, user_test, usernum, itemnum] = dataset\n",
    "len(user_train), user_train[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[user_train, user_valid, user_test, usernum, itemnum] = dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def data_partition_window_1(fname):\n",
    "    usernum = 0\n",
    "    itemnum = 0\n",
    "    User = defaultdict(list)\n",
    "    split_percent = 0.8\n",
    "\n",
    "    user_train = {}\n",
    "    user_valid = {}\n",
    "    user_test = {}\n",
    "    # assume user/item index starting from 1\n",
    "    f = open('%s.txt' % fname, 'r')\n",
    "    # read from each line\n",
    "    for line in f:\n",
    "        u, i = line.rstrip().split(' ')\n",
    "        u = int(u)\n",
    "        i = int(i)\n",
    "        usernum = max(u, usernum)\n",
    "        itemnum = max(i, itemnum)\n",
    "        User[u].append(i)\n",
    "    # read from each user\n",
    "    count = 0\n",
    "    for user in User:\n",
    "        nfeedback = len(User[user])\n",
    "        if nfeedback < 3:\n",
    "            user_train[user] = User[user]\n",
    "            user_valid[user] = []\n",
    "            user_test[user] = []\n",
    "        else:\n",
    "            # select the whole training seq\n",
    "            # user_train[user] = User[user][:-2]\n",
    "            train_seq = User[user][:-2]\n",
    "            train_seq_length = len(train_seq)\n",
    "            split_index = int(train_seq_length * split_percent)\n",
    "            input_seq = train_seq[:split_index]\n",
    "            target_seq = train_seq[split_index:]\n",
    "            for target in target_seq:\n",
    "                count += 1\n",
    "                user_train[count] = input_seq + [target]\n",
    "            user_valid[user] = []\n",
    "            user_valid[user].append(User[user][-2])\n",
    "            user_test[user] = []\n",
    "            user_test[user].append(User[user][-1])\n",
    "    usernum = count\n",
    "    return [user_train, user_valid, user_test, usernum, itemnum]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = data_partition_window_1('ml-1m')\n",
    "[user_train, user_valid, user_test, usernum, itemnum] = dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(user_train), user_train[101442]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "user = np.random.randint(1, usernum + 1)\n",
    "user"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation metrix modification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def data_partition(fname):\n",
    "    usernum = 0\n",
    "    itemnum = 0\n",
    "    User = defaultdict(list)\n",
    "    user_train = {}\n",
    "    user_valid = {}\n",
    "    user_test = {}\n",
    "    # assume user/item index starting from 1\n",
    "    f = open('%s.txt' % fname, 'r')\n",
    "    for line in f:\n",
    "        u, i = line.rstrip().split(' ')\n",
    "        u = int(u)\n",
    "        i = int(i)\n",
    "        usernum = max(u, usernum)\n",
    "        itemnum = max(i, itemnum)\n",
    "        User[u].append(i)\n",
    "\n",
    "    for user in User:\n",
    "        nfeedback = len(User[user])\n",
    "        if nfeedback < 3:\n",
    "            user_train[user] = User[user]\n",
    "            user_valid[user] = []\n",
    "            user_test[user] = []\n",
    "        else:\n",
    "            user_train[user] = User[user][:-2]\n",
    "            user_valid[user] = []\n",
    "            user_valid[user].append(User[user][-2])\n",
    "            user_test[user] = []\n",
    "            user_test[user].append(User[user][-1])\n",
    "    return [user_train, user_valid, user_test, usernum, itemnum]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = data_partition('ml-1m')\n",
    "dataset[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "def evaluate_window_valid(model, dataset, args):\n",
    "    [train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)\n",
    "    Recall = 0.0\n",
    "    P90 = 0.0\n",
    "    # P90 coverage means the smallest item sets that appear in the top 10 lists of at least 90% of the users.\n",
    "    valid_user = 0.0\n",
    "    sample_nums = 500\n",
    "    random_items = random.sample(range(1, itemnum + 1), sample_nums)\n",
    "    # if usernum > 10000:\n",
    "    #     # avoid too many training users\n",
    "    #     # keep at most 10000 users\n",
    "    #     users = random.sample(range(1, usernum + 1), 10000)\n",
    "    # else:\n",
    "    #     # else keep all the users\n",
    "    #     users = range(1, usernum + 1)\n",
    "    users = range(1, usernum+1)\n",
    "    for u in users:\n",
    "        # make sure the sequence can be validated\n",
    "        if len(train[u]) < 1 or len(valid[u]) < 1: continue\n",
    "        seq = np.zeros([args.maxlen], dtype=np.int32)\n",
    "        idx = args.maxlen - 1\n",
    "        for i in reversed(train[u]):\n",
    "            seq[idx] = i\n",
    "            # fill the sequence from end to beginning\n",
    "            idx -= 1\n",
    "            if idx == -1: break\n",
    "            # select the max len or all of the training data in the sequence\n",
    "            # limit the length, seq contains the actual training sequence\n",
    "        rated = set(train[u])\n",
    "        rated.add(0)\n",
    "        # all items interacted by the current user\n",
    "        item_idx = [valid[u][0]]\n",
    "        # get the index of validated item\n",
    "        for _ in range(100):\n",
    "            # negative sampling\n",
    "            t = np.random.randint(1, itemnum + 1)\n",
    "            # randomly sample 100 items\n",
    "            while t in rated: t = np.random.randint(1, itemnum + 1)\n",
    "            item_idx.append(t)\n",
    "        predictions = -model.predict(*[np.array(l) for l in [[u], [seq], item_idx]])\n",
    "        # predicting the recommendation list\n",
    "        predictions = predictions[0]\n",
    "        rank = predictions.argsort().argsort()[0].item()\n",
    "        # the rank of the expected next single item\n",
    "        valid_user += 1\n",
    "        if rank < 10:\n",
    "            Recall += 1\n",
    "            # P90 coverage\n",
    "        if valid_user % 100 == 0:\n",
    "            print('.', end=\"\")\n",
    "            sys.stdout.flush()\n",
    "    return Recall / valid_user, P90 / valid_user"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def str2bool(s):\n",
    "    if s not in {'false', 'true'}:\n",
    "        raise ValueError('Not a valid boolean string')\n",
    "    return s == 'true'\n",
    "\n",
    "def create_args(args):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dataset', required=True)\n",
    "    parser.add_argument('--train_dir', required=True)\n",
    "    parser.add_argument('--batch_size', default=128, type=int)\n",
    "    parser.add_argument('--lr', default=0.001, type=float)\n",
    "    parser.add_argument('--maxlen', default=50, type=int)\n",
    "    parser.add_argument('--hidden_units', default=50, type=int)\n",
    "    parser.add_argument('--num_blocks', default=2, type=int)\n",
    "    parser.add_argument('--num_epochs', default=201, type=int)\n",
    "    parser.add_argument('--num_heads', default=1, type=int)\n",
    "    parser.add_argument('--dropout_rate', default=0.5, type=float)\n",
    "    parser.add_argument('--l2_emb', default=0.0, type=float)\n",
    "    parser.add_argument('--device', default='cpu', type=str)\n",
    "    parser.add_argument('--inference_only', default=False, type=str2bool)\n",
    "    parser.add_argument('--state_dict_path', default=None, type=str)\n",
    "    args = parser.parse_args(args)\n",
    "    return args"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from models.SASRec.model import SASRec\n",
    "[train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)\n",
    "model_path = '../../processed/ml-1m_repro2/SASRec.epoch=201.lr=0.001.layer=2.head=1.hidden=50.maxlen=200.pth'\n",
    "# args.device = 'ml-1m'\n",
    "# args.train_dir = 'test'\n",
    "# args.state_dict_path = model_path\n",
    "# args.inference\n",
    "args = create_args(['--dataset','ml-1m',\n",
    "                    '--train_dir', 'test',\n",
    "                    '--device', 'cuda',\n",
    "                    '--state_dict_path', model_path,\n",
    "                    '--inference_only', 'true',\n",
    "                    '--maxlen', '200'])\n",
    "# print(args.dataset)\n",
    "model = SASRec(usernum, itemnum, args).to(args.device) # no ReLU activation in original SASRec implementation?\n",
    "model.load_state_dict(torch.load(args.state_dict_path, map_location=torch.device(args.device)))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# seq = np.zeros([200], dtype=np.int32)\n",
    "from collections import Counter\n",
    "\n",
    "def window_eval(model, dataset, args):\n",
    "    [train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)\n",
    "    Recall = 0.0\n",
    "    P90 = 0.0\n",
    "    coverage_list = []\n",
    "    # P90 coverage means the smallest item sets that appear in the top 10 lists of at least 90% of the users.\n",
    "    valid_user = 0.0\n",
    "    sample_nums = 100\n",
    "    random_items = random.sample(range(1, itemnum + 1), sample_nums)\n",
    "    sample_idx = random_items\n",
    "    sample_idx_tensor = torch.tensor(sample_idx).to(args.device)\n",
    "    users = range(1, usernum+1)\n",
    "    for u in users:\n",
    "        if len(train[u]) < 1 or len(valid[u]) < 1: continue\n",
    "        seq = np.zeros([args.maxlen], dtype=np.int32)\n",
    "        idx = args.maxlen - 1\n",
    "        for i in reversed(train[u]):\n",
    "            seq[idx] = i\n",
    "            # fill the sequence from end to beginning\n",
    "            idx -= 1\n",
    "            if idx == -1: break\n",
    "            # select the max len or all of the training data in the sequence\n",
    "            # limit the length, seq contains the actual training sequence\n",
    "        # interacted items\n",
    "        rated = set(train[u])\n",
    "        rated.add(0)\n",
    "        # ground truth item\n",
    "        ground_truth_idx = [valid[u][0]]\n",
    "        # collect all indexes, which needs to process on\n",
    "        process_idx = ground_truth_idx + sample_idx\n",
    "        predictions = -model.predict(*[np.array(l) for l in [[u], [seq], process_idx]])[0]\n",
    "        # target distance\n",
    "        target_d = predictions[0]\n",
    "        # sampled results\n",
    "        sample_d = predictions[1:]\n",
    "        # print(len(sample_d))\n",
    "        bool_tensor = target_d >= sample_d\n",
    "        count = torch.sum(bool_tensor).item()\n",
    "        if count < 10:\n",
    "            Recall += 1\n",
    "        sorted_indices = torch.argsort(sample_d)\n",
    "        sorted_sample_idx = sample_idx_tensor[sorted_indices]\n",
    "        # take the coverage@10 for all users\n",
    "        coverage_list+=list(sorted_sample_idx[:10])\n",
    "        valid_user+=1\n",
    "    p90_list = [i.item() for i in coverage_list]\n",
    "    p90_dict = Counter(p90_list)\n",
    "    p90_sort = sorted(p90_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    total_rec = 0\n",
    "    item_count = 0\n",
    "    for _, num in p90_sort:\n",
    "        total_rec+= num\n",
    "        item_count+= 1\n",
    "        if total_rec>=0.9*10*usernum:\n",
    "            break\n",
    "    return Recall/ valid_user, item_count/sample_nums"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r_10, p90_10 = window_eval(model, dataset, args)\n",
    "r_10, p90_10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r_10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p90_10[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_user = [7,3,2,8,6,1]\n",
    "train_user[:-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
