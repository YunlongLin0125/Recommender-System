{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation metrix modification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def data_partition(fname):\n",
    "    usernum = 0\n",
    "    itemnum = 0\n",
    "    User = defaultdict(list)\n",
    "    user_train = {}\n",
    "    user_valid = {}\n",
    "    user_test = {}\n",
    "    # assume user/item index starting from 1\n",
    "    f = open('%s.txt' % fname, 'r')\n",
    "    for line in f:\n",
    "        u, i = line.rstrip().split(' ')\n",
    "        u = int(u)\n",
    "        i = int(i)\n",
    "        usernum = max(u, usernum)\n",
    "        itemnum = max(i, itemnum)\n",
    "        User[u].append(i)\n",
    "\n",
    "    for user in User:\n",
    "        nfeedback = len(User[user])\n",
    "        if nfeedback < 3:\n",
    "            user_train[user] = User[user]\n",
    "            user_valid[user] = []\n",
    "            user_test[user] = []\n",
    "        else:\n",
    "            user_train[user] = User[user][:-2]\n",
    "            user_valid[user] = []\n",
    "            user_valid[user].append(User[user][-2])\n",
    "            user_test[user] = []\n",
    "            user_test[user].append(User[user][-1])\n",
    "    return [user_train, user_valid, user_test, usernum, itemnum]\n",
    "\n",
    "dataset = data_partition('data/processed/ml-1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def data_partition_window_P(fname, valid_percent, test_percent, train_percent):\n",
    "    if valid_percent + test_percent > 0.6:\n",
    "        print('the percent you select for val/test are too high')\n",
    "        return None\n",
    "    valid_start = 1 - valid_percent - test_percent\n",
    "    test_start = 1 - test_percent\n",
    "    train_start = 1 - train_percent\n",
    "    usernum = 0\n",
    "    itemnum = 0\n",
    "    User = defaultdict(list)\n",
    "    user_train_seq = {}\n",
    "    user_train = {}\n",
    "    user_valid = {}\n",
    "    user_test = {}\n",
    "    # assume user/item index starting from 1\n",
    "    f = open('%s.txt' % fname, 'r')\n",
    "    # read from each line\n",
    "    for line in f:\n",
    "        u, i = line.rstrip().split(' ')\n",
    "        u = int(u)\n",
    "        i = int(i)\n",
    "        usernum = max(u, usernum)\n",
    "        itemnum = max(i, itemnum)\n",
    "        User[u].append(i)\n",
    "        # count user and items\n",
    "    # read from each user\n",
    "    count = 0\n",
    "    for user in User:\n",
    "        nfeedback = len(User[user])\n",
    "        if nfeedback < 3:\n",
    "            user_train[user] = User[user]\n",
    "            user_valid[user] = []\n",
    "            user_test[user] = []\n",
    "        else:\n",
    "            # select the whole training seq\n",
    "            # user_train[user] = User[user][:-2]\n",
    "            seq_len = len(User[user])\n",
    "            valid_index = int(seq_len * valid_start)\n",
    "            test_index = int(seq_len * test_start)\n",
    "            if valid_index == test_index:\n",
    "                user_train[user] = User[user]\n",
    "                user_valid[user] = []\n",
    "                user_test[user] = []\n",
    "            else:\n",
    "                train_seq = User[user][: valid_index]\n",
    "                valid_seq = User[user][valid_index: test_index]\n",
    "                test_seq = User[user][test_index:]\n",
    "                train_seq_length = len(train_seq)\n",
    "                split_index = int(train_seq_length * train_start)\n",
    "                input_seq = train_seq[:split_index]\n",
    "                target_seq = train_seq[split_index:]\n",
    "                for target in target_seq:\n",
    "                    count += 1\n",
    "                    user_train[count] = input_seq + [target]\n",
    "                user_train_seq[user] = []\n",
    "                user_train_seq[user] += train_seq\n",
    "                user_valid[user] = []\n",
    "                user_valid[user] += valid_seq\n",
    "                user_test[user] = []\n",
    "                user_test[user] += test_seq\n",
    "    return [user_train, user_train_seq, user_valid, user_test, usernum, itemnum]\n",
    "\n",
    "dataset_window = data_partition_window_P('data/processed/ml-1m', 0.1, 0.1, 0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "from collections import Counter\n",
    "import sys\n",
    "\n",
    "def evaluate_window_valid(model, dataset, dataset_window, args):\n",
    "    [train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)\n",
    "    [_, train, valid, test, _, itemnum] = copy.deepcopy(dataset_window)\n",
    "    Recall = 0.0\n",
    "    Recall_U = 0.0\n",
    "    coverage_list = []\n",
    "    # P90 coverage means the smallest item sets that appear in the top 10 lists of at least 90% of the users.\n",
    "    valid_user = 0.0\n",
    "    sample_nums = 500\n",
    "    random_items = random.sample(range(1, itemnum + 1), sample_nums)\n",
    "    sample_idx = random_items\n",
    "    sample_idx_tensor = torch.tensor(sample_idx).to(args.device)\n",
    "    users = range(1, usernum + 1)\n",
    "    for u in users:\n",
    "        if len(train[u]) < 1 or len(valid[u]) < 1: continue\n",
    "        seq = np.zeros([args.maxlen], dtype=np.int32)\n",
    "        idx = args.maxlen - 1\n",
    "        for i in reversed(train[u]):\n",
    "            seq[idx] = i\n",
    "            # fill the sequence from end to beginning\n",
    "            idx -= 1\n",
    "            if idx == -1: break\n",
    "            # select the max len or all of the training data in the sequence\n",
    "            # limit the length, seq contains the actual training sequence\n",
    "        # interacted items\n",
    "        rated = set(train[u])\n",
    "        rated.add(0)\n",
    "        # ground truth item\n",
    "        ground_truth_idx = valid[u]\n",
    "        valid_num = len(valid[u])\n",
    "        # collect all indexes, which needs to process on\n",
    "        process_idx = ground_truth_idx + sample_idx\n",
    "        predictions = -model.predict(*[np.array(l) for l in [[u], [seq], process_idx]])[0]\n",
    "        # target distance\n",
    "        target_ds = predictions[:valid_num]\n",
    "        # sampled results\n",
    "        sample_d = predictions[valid_num:]\n",
    "        # print(len(sample_d))\n",
    "        for target_d in target_ds:\n",
    "            bool_tensor = target_d >= sample_d\n",
    "            count = torch.sum(bool_tensor).item()\n",
    "            if count < 10:\n",
    "                Recall_U += 1\n",
    "        Recall_U = Recall_U / valid_num\n",
    "        Recall += Recall_U\n",
    "        Recall_U = 0\n",
    "        sorted_indices = torch.argsort(sample_d)\n",
    "        sorted_sample_idx = sample_idx_tensor[sorted_indices]\n",
    "        # take the coverage@10 for all users\n",
    "        coverage_list += list(sorted_sample_idx[:10])\n",
    "        valid_user += 1\n",
    "        if valid_user % 100 == 0:\n",
    "            print('.', end=\"\")\n",
    "            sys.stdout.flush()\n",
    "    p90_list = [i.item() for i in coverage_list]\n",
    "    p90_dict = Counter(p90_list)\n",
    "    p90_sort = sorted(p90_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    total_rec = 0\n",
    "    item_count = 0\n",
    "    for _, num in p90_sort:\n",
    "        total_rec += num\n",
    "        item_count += 1\n",
    "        if total_rec >= 0.9 * 10 * usernum:\n",
    "            break\n",
    "    return Recall / valid_user, item_count / sample_nums"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def str2bool(s):\n",
    "    if s not in {'false', 'true'}:\n",
    "        raise ValueError('Not a valid boolean string')\n",
    "    return s == 'true'\n",
    "\n",
    "def create_args(args):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dataset', required=True)\n",
    "    parser.add_argument('--train_dir', required=True)\n",
    "    parser.add_argument('--batch_size', default=128, type=int)\n",
    "    parser.add_argument('--lr', default=0.001, type=float)\n",
    "    parser.add_argument('--maxlen', default=50, type=int)\n",
    "    parser.add_argument('--hidden_units', default=50, type=int)\n",
    "    parser.add_argument('--num_blocks', default=2, type=int)\n",
    "    parser.add_argument('--num_epochs', default=201, type=int)\n",
    "    parser.add_argument('--num_heads', default=1, type=int)\n",
    "    parser.add_argument('--dropout_rate', default=0.5, type=float)\n",
    "    parser.add_argument('--l2_emb', default=0.0, type=float)\n",
    "    parser.add_argument('--device', default='cpu', type=str)\n",
    "    parser.add_argument('--inference_only', default=False, type=str2bool)\n",
    "    parser.add_argument('--state_dict_path', default=None, type=str)\n",
    "    parser.add_argument('--window_predictor', default=False, type=str2bool)\n",
    "    parser.add_argument('--window_eval', default=False, type=str2bool)\n",
    "    parser.add_argument('--eval_epoch', default=20, type=int)\n",
    "    args = parser.parse_args(args)\n",
    "    return args"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.SASRec.model import SASRec\n",
    "[train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)\n",
    "model_path = 'processed/ml-1m_repro2/SASRec.epoch=201.lr=0.001.layer=2.head=1.hidden=50.maxlen=200.pth'\n",
    "# args.device = 'ml-1m'\n",
    "# args.train_dir = 'test'\n",
    "# args.state_dict_path = model_path\n",
    "# args.inference\n",
    "args = create_args(['--dataset','ml-1m',\n",
    "                    '--train_dir', 'test',\n",
    "                    '--device', 'cuda',\n",
    "                    '--state_dict_path', model_path,\n",
    "                    '--inference_only', 'true',\n",
    "                    '--maxlen', '200'])\n",
    "# print(args.dataset)\n",
    "model = SASRec(usernum, itemnum, args).to(args.device) # no ReLU activation in original SASRec implementation?\n",
    "model.load_state_dict(torch.load(args.state_dict_path, map_location=torch.device(args.device)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................"
     ]
    },
    {
     "data": {
      "text/plain": "(0.35887693968618883, 0.338)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_10, p90_10 = evaluate_window_valid(model, dataset, dataset_window, args)\n",
    "r_10, p90_10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "[train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)\n",
    "[_, train, valid, test, _, itemnum] = copy.deepcopy(dataset_window)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "Recall = 0.0\n",
    "Recall_U = 0.0\n",
    "coverage_list = []\n",
    "# P90 coverage means the smallest item sets that appear in the top 10 lists of at least 90% of the users.\n",
    "valid_user = 0.0\n",
    "sample_nums = 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "([1,\n  2,\n  3,\n  4,\n  5,\n  6,\n  7,\n  8,\n  9,\n  10,\n  11,\n  12,\n  13,\n  14,\n  15,\n  16,\n  17,\n  18,\n  19,\n  20,\n  21,\n  22,\n  23,\n  24,\n  25,\n  26,\n  27,\n  28,\n  29,\n  30,\n  31,\n  32,\n  33,\n  34,\n  35,\n  36,\n  37,\n  38,\n  39,\n  40,\n  41,\n  42],\n [43, 44, 45, 46, 47],\n [48, 49, 50, 51, 52, 53])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1], valid[1], test[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "\n",
    "random_items = random.sample(range(1, itemnum + 1), sample_nums)\n",
    "sample_idx = random_items\n",
    "sample_idx_tensor = torch.tensor(sample_idx).to(args.device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1.0\n",
      "10\n",
      "1.7692307692307692\n"
     ]
    }
   ],
   "source": [
    "Recall,valid_user,p90_list, coverage_list = 0, 0, [], []\n",
    "for u in [1,2]:\n",
    "    seq = np.zeros([args.maxlen], dtype=np.int32)\n",
    "    idx = args.maxlen - 1\n",
    "    for i in reversed(train[u]):\n",
    "        seq[idx] = i\n",
    "        # fill the sequence from end to beginning\n",
    "        idx -= 1\n",
    "        if idx == -1: break\n",
    "        # select the max len or all of the training data in the sequence\n",
    "        # limit the length, seq contains the actual training sequence\n",
    "    # interacted items\n",
    "    rated = set(train[u])\n",
    "    rated.add(0)\n",
    "    # ground truth item\n",
    "    ground_truth_idx = valid[u]\n",
    "    valid_num = len(valid[u])\n",
    "    # collect all indexes, which needs to process on\n",
    "    process_idx = ground_truth_idx + sample_idx\n",
    "    predictions = -model.predict(*[np.array(l) for l in [[u], [seq], process_idx]])[0]\n",
    "    target_ds = predictions[:valid_num]\n",
    "        # sampled results\n",
    "    sample_d = predictions[valid_num:]\n",
    "        # print(len(sample_d))\n",
    "    for target_d in target_ds:\n",
    "        bool_tensor = target_d >= sample_d\n",
    "        count = torch.sum(bool_tensor).item()\n",
    "        if count < 10:\n",
    "            Recall_U += 1\n",
    "    print(Recall_U)\n",
    "    Recall_U = Recall_U / valid_num\n",
    "    Recall += Recall_U\n",
    "    print(Recall)\n",
    "    Recall_U = 0\n",
    "    sorted_indices = torch.argsort(sample_d)\n",
    "    sorted_sample_idx = sample_idx_tensor[sorted_indices]\n",
    "    # take the coverage@10 for all users\n",
    "    coverage_list += list(sorted_sample_idx[:10])\n",
    "    valid_user += 1\n",
    "    if valid_user % 100 == 0:\n",
    "        print('.', end=\"\")\n",
    "        sys.stdout.flush()\n",
    "    p90_list = [i.item() for i in coverage_list]\n",
    "    p90_dict = Counter(p90_list)\n",
    "    p90_sort = sorted(p90_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    total_rec = 0\n",
    "    item_count = 0\n",
    "    for _, num in p90_sort:\n",
    "        total_rec += num\n",
    "        item_count += 1\n",
    "        if total_rec >= 0.9 * 10 * usernum:\n",
    "                break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  2  3  4  5  6  7  8  9 10\n",
      "  11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34\n",
      "  35 36 37 38 39 40 41 42]] [  43   44   45   46   47 1872 2909  104 1447 2452 1112 1419 2951 1965\n",
      " 1730 2632 1233  832 3387  383 3196 1528 1224  457 3107 3164 3108 2847\n",
      "  542  515 2793 2035 1199 3263 2806 2423  672 1345 1492  687 1436  549\n",
      " 2474 1790 3025  826  406 2437 2817  580 1731 2770   65 1865 2824 3272\n",
      " 1524  198 1611 2980 1494  252 2778 1548 1047 2118 1406  178   51 2695\n",
      " 2123  444   63 2331  410 1149 2840 3382 3368 1163 2720 1918  868 2936\n",
      " 1071 1170 2055  618 1953 2057 2725 3256  503 2810 1295 2042 1495 1699\n",
      "  854  364  583 1443 1263  952 3048]\n"
     ]
    }
   ],
   "source": [
    "print(*[np.array(l) for l in [[u], [seq], process_idx]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([105]), 105)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.size(), len(process_idx)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "([54,\n  55,\n  56,\n  57,\n  58,\n  59,\n  60,\n  11,\n  61,\n  62,\n  63,\n  64,\n  65,\n  8,\n  66,\n  67,\n  68,\n  69,\n  70,\n  71,\n  72,\n  73,\n  74,\n  75,\n  76,\n  77,\n  18,\n  78,\n  79,\n  80,\n  81,\n  82,\n  83,\n  20,\n  84,\n  85,\n  86,\n  87,\n  88,\n  89,\n  90,\n  91,\n  92,\n  93,\n  94,\n  95,\n  96,\n  97,\n  98,\n  99,\n  100,\n  101,\n  102,\n  103,\n  104,\n  105,\n  106,\n  107,\n  108,\n  109,\n  110,\n  111,\n  112,\n  113,\n  114,\n  115,\n  116,\n  117,\n  118,\n  119,\n  30,\n  120,\n  121,\n  122,\n  123,\n  124,\n  37,\n  125,\n  126,\n  127,\n  128,\n  129,\n  130,\n  131,\n  17,\n  132,\n  133,\n  134,\n  135,\n  136,\n  137,\n  138,\n  139,\n  140,\n  141,\n  142,\n  143,\n  144,\n  145,\n  146,\n  147,\n  148,\n  149],\n [150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162],\n [163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175])"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[u], valid[u], test[u]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "# predictions = -model.predict(*[np.array(l) for l in [[u], [seq], process_idx]])[0]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.8846153846153846, 0.16)"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recall / valid_user, item_count / sample_nums"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
