{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation metrix modification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def data_partition(fname):\n",
    "    usernum = 0\n",
    "    itemnum = 0\n",
    "    User = defaultdict(list)\n",
    "    user_train = {}\n",
    "    user_valid = {}\n",
    "    user_test = {}\n",
    "    # assume user/item index starting from 1\n",
    "    f = open('%s.txt' % fname, 'r')\n",
    "    for line in f:\n",
    "        u, i = line.rstrip().split(' ')\n",
    "        u = int(u)\n",
    "        i = int(i)\n",
    "        usernum = max(u, usernum)\n",
    "        itemnum = max(i, itemnum)\n",
    "        User[u].append(i)\n",
    "\n",
    "    for user in User:\n",
    "        nfeedback = len(User[user])\n",
    "        if nfeedback < 3:\n",
    "            user_train[user] = User[user]\n",
    "            user_valid[user] = []\n",
    "            user_test[user] = []\n",
    "        else:\n",
    "            user_train[user] = User[user][:-2]\n",
    "            user_valid[user] = []\n",
    "            user_valid[user].append(User[user][-2])\n",
    "            user_test[user] = []\n",
    "            user_test[user].append(User[user][-1])\n",
    "    return [user_train, user_valid, user_test, usernum, itemnum]\n",
    "\n",
    "dataset = data_partition('data/processed/ml-1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "def evaluate_window_valid(model, dataset, args):\n",
    "    [train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)\n",
    "    Recall = 0.0\n",
    "    P90 = 0.0\n",
    "    # P90 coverage means the smallest item sets that appear in the top 10 lists of at least 90% of the users.\n",
    "    valid_user = 0.0\n",
    "    sample_nums = 500\n",
    "    random_items = random.sample(range(1, itemnum + 1), sample_nums)\n",
    "    # if usernum > 10000:\n",
    "    #     # avoid too many training users\n",
    "    #     # keep at most 10000 users\n",
    "    #     users = random.sample(range(1, usernum + 1), 10000)\n",
    "    # else:\n",
    "    #     # else keep all the users\n",
    "    #     users = range(1, usernum + 1)\n",
    "    users = range(1, usernum+1)\n",
    "    for u in users:\n",
    "        # make sure the sequence can be validated\n",
    "        if len(train[u]) < 1 or len(valid[u]) < 1: continue\n",
    "        seq = np.zeros([args.maxlen], dtype=np.int32)\n",
    "        idx = args.maxlen - 1\n",
    "        for i in reversed(train[u]):\n",
    "            seq[idx] = i\n",
    "            # fill the sequence from end to beginning\n",
    "            idx -= 1\n",
    "            if idx == -1: break\n",
    "            # select the max len or all of the training data in the sequence\n",
    "            # limit the length, seq contains the actual training sequence\n",
    "        rated = set(train[u])\n",
    "        rated.add(0)\n",
    "        # all items interacted by the current user\n",
    "        item_idx = [valid[u][0]]\n",
    "        # get the index of validated item\n",
    "        for _ in range(100):\n",
    "            # negative sampling\n",
    "            t = np.random.randint(1, itemnum + 1)\n",
    "            # randomly sample 100 items\n",
    "            while t in rated: t = np.random.randint(1, itemnum + 1)\n",
    "            item_idx.append(t)\n",
    "        predictions = -model.predict(*[np.array(l) for l in [[u], [seq], item_idx]])\n",
    "        # predicting the recommendation list\n",
    "        predictions = predictions[0]\n",
    "        rank = predictions.argsort().argsort()[0].item()\n",
    "        # the rank of the expected next single item\n",
    "        valid_user += 1\n",
    "        if rank < 10:\n",
    "            Recall += 1\n",
    "            # P90 coverage\n",
    "        if valid_user % 100 == 0:\n",
    "            print('.', end=\"\")\n",
    "            sys.stdout.flush()\n",
    "    return Recall / valid_user, P90 / valid_user"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def str2bool(s):\n",
    "    if s not in {'false', 'true'}:\n",
    "        raise ValueError('Not a valid boolean string')\n",
    "    return s == 'true'\n",
    "\n",
    "def create_args(args):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dataset', required=True)\n",
    "    parser.add_argument('--train_dir', required=True)\n",
    "    parser.add_argument('--batch_size', default=128, type=int)\n",
    "    parser.add_argument('--lr', default=0.001, type=float)\n",
    "    parser.add_argument('--maxlen', default=50, type=int)\n",
    "    parser.add_argument('--hidden_units', default=50, type=int)\n",
    "    parser.add_argument('--num_blocks', default=2, type=int)\n",
    "    parser.add_argument('--num_epochs', default=201, type=int)\n",
    "    parser.add_argument('--num_heads', default=1, type=int)\n",
    "    parser.add_argument('--dropout_rate', default=0.5, type=float)\n",
    "    parser.add_argument('--l2_emb', default=0.0, type=float)\n",
    "    parser.add_argument('--device', default='cpu', type=str)\n",
    "    parser.add_argument('--inference_only', default=False, type=str2bool)\n",
    "    parser.add_argument('--state_dict_path', default=None, type=str)\n",
    "    args = parser.parse_args(args)\n",
    "    return args"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.SASRec.model import SASRec\n",
    "[train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)\n",
    "model_path = 'processed/ml-1m_repro2/SASRec.epoch=201.lr=0.001.layer=2.head=1.hidden=50.maxlen=200.pth'\n",
    "# args.device = 'ml-1m'\n",
    "# args.train_dir = 'test'\n",
    "# args.state_dict_path = model_path\n",
    "# args.inference\n",
    "args = create_args(['--dataset','ml-1m',\n",
    "                    '--train_dir', 'test',\n",
    "                    '--device', 'cuda',\n",
    "                    '--state_dict_path', model_path,\n",
    "                    '--inference_only', 'true',\n",
    "                    '--maxlen', '200'])\n",
    "# print(args.dataset)\n",
    "model = SASRec(usernum, itemnum, args).to(args.device) # no ReLU activation in original SASRec implementation?\n",
    "model.load_state_dict(torch.load(args.state_dict_path, map_location=torch.device(args.device)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# seq = np.zeros([200], dtype=np.int32)\n",
    "from collections import Counter\n",
    "\n",
    "def window_eval(model, dataset, args):\n",
    "    [train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)\n",
    "    Recall = 0.0\n",
    "    P90 = 0.0\n",
    "    coverage_list = []\n",
    "    # P90 coverage means the smallest item sets that appear in the top 10 lists of at least 90% of the users.\n",
    "    valid_user = 0.0\n",
    "    sample_nums = 100\n",
    "    random_items = random.sample(range(1, itemnum + 1), sample_nums)\n",
    "    sample_idx = random_items\n",
    "    sample_idx_tensor = torch.tensor(sample_idx).to(args.device)\n",
    "    users = range(1, usernum+1)\n",
    "    for u in users:\n",
    "        if len(train[u]) < 1 or len(valid[u]) < 1: continue\n",
    "        seq = np.zeros([args.maxlen], dtype=np.int32)\n",
    "        idx = args.maxlen - 1\n",
    "        for i in reversed(train[u]):\n",
    "            seq[idx] = i\n",
    "            # fill the sequence from end to beginning\n",
    "            idx -= 1\n",
    "            if idx == -1: break\n",
    "            # select the max len or all of the training data in the sequence\n",
    "            # limit the length, seq contains the actual training sequence\n",
    "        # interacted items\n",
    "        rated = set(train[u])\n",
    "        rated.add(0)\n",
    "        # ground truth item\n",
    "        ground_truth_idx = [valid[u][0]]\n",
    "        # collect all indexes, which needs to process on\n",
    "        process_idx = ground_truth_idx + sample_idx\n",
    "        predictions = -model.predict(*[np.array(l) for l in [[u], [seq], process_idx]])[0]\n",
    "        # target distance\n",
    "        target_d = predictions[0]\n",
    "        # sampled results\n",
    "        sample_d = predictions[1:]\n",
    "        # print(len(sample_d))\n",
    "        bool_tensor = target_d >= sample_d\n",
    "        count = torch.sum(bool_tensor).item()\n",
    "        if count < 10:\n",
    "            Recall += 1\n",
    "        sorted_indices = torch.argsort(sample_d)\n",
    "        sorted_sample_idx = sample_idx_tensor[sorted_indices]\n",
    "        # take the coverage@10 for all users\n",
    "        coverage_list+=list(sorted_sample_idx[:10])\n",
    "        valid_user+=1\n",
    "    p90_list = [i.item() for i in coverage_list]\n",
    "    p90_dict = Counter(p90_list)\n",
    "    p90_sort = sorted(p90_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    total_rec = 0\n",
    "    item_count = 0\n",
    "    for _, num in p90_sort:\n",
    "        total_rec+= num\n",
    "        item_count+= 1\n",
    "        if total_rec>=0.9*10*usernum:\n",
    "            break\n",
    "    return Recall/ valid_user, item_count/sample_nums"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.7357615894039735, 0.43)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_10, p90_10 = window_eval(model, dataset, args)\n",
    "r_10, p90_10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mSASRec\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m evaluate\n\u001B[0;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m----> 3\u001B[0m t_test \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Recommender-System\\models\\SASRec\\utils.py:142\u001B[0m, in \u001B[0;36mevaluate\u001B[1;34m(model, dataset, args)\u001B[0m\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m rated: t \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandint(\u001B[38;5;241m1\u001B[39m, itemnum \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    140\u001B[0m     item_idx\u001B[38;5;241m.\u001B[39mappend(t)\n\u001B[1;32m--> 142\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43ml\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ml\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43mu\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mseq\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mitem_idx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    143\u001B[0m predictions \u001B[38;5;241m=\u001B[39m predictions[\u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# - for 1st argsort DESC\u001B[39;00m\n\u001B[0;32m    145\u001B[0m rank \u001B[38;5;241m=\u001B[39m predictions\u001B[38;5;241m.\u001B[39margsort()\u001B[38;5;241m.\u001B[39margsort()[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32m~\\Desktop\\Recommender-System\\models\\SASRec\\model.py:111\u001B[0m, in \u001B[0;36mSASRec.predict\u001B[1;34m(self, user_ids, log_seqs, item_indices)\u001B[0m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, user_ids, log_seqs, item_indices): \u001B[38;5;66;03m# for inference\u001B[39;00m\n\u001B[1;32m--> 111\u001B[0m     log_feats \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog2feats\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlog_seqs\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# user_ids hasn't been used yet\u001B[39;00m\n\u001B[0;32m    113\u001B[0m     final_feat \u001B[38;5;241m=\u001B[39m log_feats[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, :] \u001B[38;5;66;03m# only use last QKV classifier, a waste\u001B[39;00m\n\u001B[0;32m    115\u001B[0m     item_embs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitem_emb(torch\u001B[38;5;241m.\u001B[39mLongTensor(item_indices)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdev)) \u001B[38;5;66;03m# (U, I, C)\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Recommender-System\\models\\SASRec\\model.py:88\u001B[0m, in \u001B[0;36mSASRec.log2feats\u001B[1;34m(self, log_seqs)\u001B[0m\n\u001B[0;32m     85\u001B[0m seqs \u001B[38;5;241m=\u001B[39m Q \u001B[38;5;241m+\u001B[39m mha_outputs\n\u001B[0;32m     86\u001B[0m seqs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtranspose(seqs, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 88\u001B[0m seqs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_layernorms\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseqs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     89\u001B[0m seqs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward_layers[i](seqs)\n\u001B[0;32m     90\u001B[0m seqs \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m  \u001B[38;5;241m~\u001B[39mtimeline_mask\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\normalization.py:190\u001B[0m, in \u001B[0;36mLayerNorm.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    191\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalized_shape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2515\u001B[0m, in \u001B[0;36mlayer_norm\u001B[1;34m(input, normalized_shape, weight, bias, eps)\u001B[0m\n\u001B[0;32m   2511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_variadic(\u001B[38;5;28minput\u001B[39m, weight, bias):\n\u001B[0;32m   2512\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m   2513\u001B[0m         layer_norm, (\u001B[38;5;28minput\u001B[39m, weight, bias), \u001B[38;5;28minput\u001B[39m, normalized_shape, weight\u001B[38;5;241m=\u001B[39mweight, bias\u001B[38;5;241m=\u001B[39mbias, eps\u001B[38;5;241m=\u001B[39meps\n\u001B[0;32m   2514\u001B[0m     )\n\u001B[1;32m-> 2515\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer_norm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalized_shape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackends\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcudnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menabled\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from models.SASRec.utils import evaluate\n",
    "model.eval()\n",
    "t_test = evaluate(model, dataset, args)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
